{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n",
      "/var/folders/8z/96_p5y5s313_8b55fgygvygh0000gn/T/ipykernel_66867/2030107288.py:10: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  data = data.stack(level=0).rename_axis(['Date', 'Ticker']).reset_index(level=1)\n",
      "[*********************100%***********************]  4 of 4 completed\n",
      "/var/folders/8z/96_p5y5s313_8b55fgygvygh0000gn/T/ipykernel_66867/2030107288.py:10: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  data = data.stack(level=0).rename_axis(['Date', 'Ticker']).reset_index(level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to /Users/amitkumar/Documents/Screener/combined_equity_data.csv\n",
      "Saved data to /Users/amitkumar/Documents/Screener/filtered_equity_data_with_camarilla.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "def download_stock_data(symbols, timeframes, period=\"1mo\"):\n",
    "    all_data = []\n",
    "    for timeframe in timeframes:\n",
    "        data = yf.download(symbols, group_by='Ticker', period=period, interval=timeframe)\n",
    "        data = data.stack(level=0).rename_axis(['Date', 'Ticker']).reset_index(level=1)\n",
    "        data[\"Timeframe\"] = timeframe\n",
    "        data[\"Datetime\"] = data.index\n",
    "        \n",
    "        # Convert 'Datetime' column to UTC\n",
    "        data['Datetime'] = pd.to_datetime(data['Datetime'], utc=True)\n",
    "        \n",
    "        # Convert 'Datetime' column to 'Asia/Kolkata' time zone\n",
    "        data['Datetime_India'] = data['Datetime'].dt.tz_convert(pytz.timezone('Asia/Kolkata'))\n",
    "        \n",
    "        # Split Datetime into Date, Time, and Timezone columns\n",
    "        data['Date'] = data['Datetime_India'].dt.date\n",
    "        data['Time'] = data['Datetime_India'].dt.time\n",
    "        data['Timezone'] = data['Datetime_India'].dt.tz.zone\n",
    "        # Add Camarilla levels for 1d timeframe\n",
    "        if timeframe == \"1d\":\n",
    "            data = calculate_camarilla_levels(data)\n",
    "        \n",
    "        all_data.append(data)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def calculate_camarilla_levels(data):\n",
    "    \n",
    "    # Camarilla pivot levels\n",
    "    \n",
    "    data[\"H\"] = data[\"High\"]\n",
    "    data[\"L\"] = data[\"Low\"]\n",
    "    data[\"C\"] = data[\"Close\"]\n",
    "\n",
    "    data[\"H1\"] = data[\"C\"] + 1.1 * (data[\"H\"] - data[\"L\"]) / 12\n",
    "    data[\"H2\"] = data[\"C\"] + 1.1 * (data[\"H\"] - data[\"L\"]) / 6\n",
    "    data[\"H3\"] = data[\"C\"] + 1.1 * (data[\"H\"] - data[\"L\"]) / 4\n",
    "    data[\"H4\"] = data[\"C\"] + 1.1 * (data[\"H\"] - data[\"L\"]) / 2.66\n",
    "\n",
    "    data[\"L1\"] = data[\"C\"] - 1.1 * (data[\"H\"] - data[\"L\"]) / 12\n",
    "    data[\"L2\"] = data[\"C\"] - 1.1 * (data[\"H\"] - data[\"L\"]) / 6\n",
    "    data[\"L3\"] = data[\"C\"] - 1.1 * (data[\"H\"] - data[\"L\"]) / 4\n",
    "    data[\"L4\"] = data[\"C\"] - 1.1 * (data[\"H\"] - data[\"L\"]) / 2.66\n",
    "    \n",
    "    return data\n",
    "\n",
    "def filter_data_by_date(data, days_ago):\n",
    "    # Filters data for a specific date\n",
    "    \n",
    "    target_date = (datetime.now() - timedelta(days=days_ago)).date()\n",
    "    return data[data['Date'] == target_date]\n",
    "\n",
    "def save_to_csv(data, filepath):\n",
    "    # Saves the given DataFrame to a CSV file.\n",
    "    \n",
    "    data.to_csv(filepath, index=False)\n",
    "    print(f\"Saved data to {filepath}\")\n",
    "\n",
    "symbols = ['VIPCLOTHNG.NS', 'HMVL.NS', 'LPDC.NS', 'GOENKA.NS']\n",
    "timeframes = [\"5m\", \"1d\"]\n",
    "\n",
    "# Historical data\n",
    "combined_data = download_stock_data(symbols, timeframes)\n",
    "save_to_csv(combined_data, \"combined_equity_data.csv\")\n",
    "\n",
    "# Filter data for yesterday\n",
    "filtered_data = filter_data_by_date(combined_data, days_ago=1)\n",
    "save_to_csv(filtered_data, \"filtered_equity_data_with_camarilla.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n",
      "/var/folders/8z/96_p5y5s313_8b55fgygvygh0000gn/T/ipykernel_66867/3546231456.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_5m_filled[['H1','H2','H3','H4','L1','L2','L3','L4']] = df_1d[['H1','H2','H3','H4','L1','L2','L3','L4']].ffill().iloc[-1]\n",
      "/var/folders/8z/96_p5y5s313_8b55fgygvygh0000gn/T/ipykernel_66867/3546231456.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_5m_filled[['H1','H2','H3','H4','L1','L2','L3','L4']] = df_1d[['H1','H2','H3','H4','L1','L2','L3','L4']].ffill().iloc[-1]\n",
      "/var/folders/8z/96_p5y5s313_8b55fgygvygh0000gn/T/ipykernel_66867/3546231456.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_5m_filled[['H1','H2','H3','H4','L1','L2','L3','L4']] = df_1d[['H1','H2','H3','H4','L1','L2','L3','L4']].ffill().iloc[-1]\n",
      "/var/folders/8z/96_p5y5s313_8b55fgygvygh0000gn/T/ipykernel_66867/3546231456.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_5m_filled[['H1','H2','H3','H4','L1','L2','L3','L4']] = df_1d[['H1','H2','H3','H4','L1','L2','L3','L4']].ffill().iloc[-1]\n",
      "/var/folders/8z/96_p5y5s313_8b55fgygvygh0000gn/T/ipykernel_66867/3546231456.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  camarilla_price_data = latest_price.groupby(['Ticker','Date'], group_keys=False).apply(camarilla_lower_tf_fill)\n"
     ]
    }
   ],
   "source": [
    "def fetch_latest_price(symbols):\n",
    "    # Convert the list of symbols to a space-separated string\n",
    "    symbols_str = \" \".join(symbols)\n",
    "    \n",
    "    # Fetch ticker data for all symbols\n",
    "    tickers = yf.Tickers(symbols_str)\n",
    "    history_data = tickers.history(period=\"1d\")\n",
    "    \n",
    "    # Extract closing prices for all symbols\n",
    "    try:\n",
    "        current_prices = history_data['Close'].iloc[-1].dropna()\n",
    "        result_df = current_prices.reset_index()\n",
    "        result_df.columns = ['Ticker', 'CurrentPrice']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        result_df = pd.DataFrame(columns=['Ticker', 'CurrentPrice'])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def camarilla_lower_tf_fill(group):\n",
    "    # Filling the 5m camarilla data\n",
    "    \n",
    "    df_1d = group[group['Timeframe'] == '1d']\n",
    "    df_5m = group[group['Timeframe'] == '5m']\n",
    "    if not df_1d.empty:\n",
    "        df_5m_filled = df_5m.copy()\n",
    "        # Fill 5m with the latest available 1d values\n",
    "        df_5m_filled[['H1','H2','H3','H4','L1','L2','L3','L4']] = df_1d[['H1','H2','H3','H4','L1','L2','L3','L4']].ffill().iloc[-1]\n",
    "        # Combine 1d and filled 5m data\n",
    "        return pd.concat([df_1d, df_5m_filled]).sort_index()\n",
    "    else:\n",
    "        return group\n",
    "\n",
    "# Current Price \n",
    "current_price = fetch_latest_price(symbols)\n",
    "latest_price = filtered_data.merge(current_price, on='Ticker', how='left')\n",
    "\n",
    "# Applying group-by using Symbol and Date\n",
    "camarilla_price_data = latest_price.groupby(['Ticker','Date'], group_keys=False).apply(camarilla_lower_tf_fill)\n",
    "\n",
    "camarilla_price_data.to_csv(\"filtered_equity_data_with_camarilla.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_close_long_H3_crossover: ['VIPCLOTHNG.NS']\n",
      "unique_current_long_price_first_candle_crossover: ['HMVL.NS' 'LPDC.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8z/96_p5y5s313_8b55fgygvygh0000gn/T/ipykernel_66867/4228054012.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  long_5m_high['H3'] = pd.to_numeric(long_5m_high['H3'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "#### Logic for Intraday Long Position \n",
    "\n",
    "long_5m_high = camarilla_price_data[(camarilla_price_data['Timeframe'] == '5m') & (camarilla_price_data['Time'].astype(str) == '09:15:00')]\n",
    "long_5m_high['H3'] = pd.to_numeric(long_5m_high['H3'], errors='coerce')\n",
    "#print('long_5m_high',long_5m_high)\n",
    "\n",
    "### H3 level price cross-over\n",
    "\n",
    "long_5m = long_5m_high[(long_5m_high['Close'] >= long_5m_high['H3']) | (long_5m_high['CurrentPrice'] >= long_5m_high['H3'])] \n",
    "long_5m_a = long_5m['Ticker'].unique()\n",
    "\n",
    "print('unique_close_long_H3_crossover:',long_5m_a)\n",
    "\n",
    "long_5m.to_csv('unique_close_long_H3_crossover.csv', index=False)\n",
    "\n",
    "### first candle high breakdown\n",
    "\n",
    "long_5m_candle = long_5m_high.merge(camarilla_price_data, on='Ticker', how='inner')\n",
    "#print('long_5m_candle',long_5m_candle)\n",
    "\n",
    "long_5m_candle_breakdown = long_5m_candle[long_5m_candle['CurrentPrice_x'] >= long_5m_candle['High_x']]\n",
    "long_5m_candle_breakdown_a = long_5m_candle_breakdown['Ticker'].unique()\n",
    "\n",
    "print('unique_current_long_price_first_candle_crossover:',long_5m_candle_breakdown_a)\n",
    "\n",
    "long_5m_candle_breakdown.to_csv('unique_current_long_price_first_candle_crossover.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_close_H3_short_crossover: ['LPDC.NS' 'VIPCLOTHNG.NS']\n",
      "unique_current_price_first_candle_crossover: ['VIPCLOTHNG.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8z/96_p5y5s313_8b55fgygvygh0000gn/T/ipykernel_66867/1399483077.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  short_5m_low['L3'] = pd.to_numeric(short_5m_low['L3'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "##### Logic for Intraday Short Position\n",
    "\n",
    "short_5m_low = camarilla_price_data[(camarilla_price_data['Timeframe'] == '5m') & (camarilla_price_data['Time'].astype(str) == '09:15:00')]\n",
    "short_5m_low['L3'] = pd.to_numeric(short_5m_low['L3'], errors='coerce')\n",
    "\n",
    "### L3 level price cross-over\n",
    "\n",
    "short_5m = short_5m_low[(short_5m_low['Close'] <= short_5m_low['L3']) | (short_5m_low['CurrentPrice'] <= short_5m_low['L3'])] \n",
    "short_5m_a = short_5m['Ticker'].unique()\n",
    "\n",
    "print('unique_close_H3_short_crossover:',short_5m_a)\n",
    "short_5m.to_csv('unique_close_H3_short_crossover.csv', index=False)\n",
    "\n",
    "short_5m_candle = short_5m_low.merge(camarilla_price_data, on='Ticker', how='inner')\n",
    "\n",
    "### first candle low breakdown\n",
    "\n",
    "short_5m_candle_breakdown = short_5m_candle[short_5m_candle['CurrentPrice_x'] <= short_5m_candle['Low_x']]\n",
    "short_5m_candle_breakdown_a = short_5m_candle_breakdown['Ticker'].unique()\n",
    "\n",
    "print('unique_current_price_first_candle_crossover:',short_5m_candle_breakdown_a)\n",
    "\n",
    "short_5m_candle_breakdown.to_csv('unique_current_price_first_candle_crossover.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
